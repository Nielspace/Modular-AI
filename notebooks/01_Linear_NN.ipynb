{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fe5df4-5903-4818-8d72-8d3571597c6d",
   "metadata": {},
   "source": [
    "# Linear Neural Networks\n",
    "\n",
    "In this notebook, we will explore the mathematical foundations and implementation of Linear Neural Networks. Linear models are the simplest form of neural networks and are primarily used for linear regression tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158649f-a43b-453e-85a2-a538c1b4f8e0",
   "metadata": {},
   "source": [
    "## Theoretical Background\n",
    "\n",
    "### Overview\n",
    "Linear Neural Networks are composed of layers where each neuron performs a linear transformation of the input.\n",
    "\n",
    "**Type of Function**: Linear\n",
    "\n",
    "**Nature**: Continuous\n",
    "\n",
    "**Behavior**: Linear neural networks are the simplest form of neural networks where the output is a linear combination of the input features. \n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "\n",
    "The output \\(y\\) is given by:\n",
    "\\[ y = XW + b1\\]\n",
    "where \\( X \\) is the input, \\( W \\) is the weight matrix, and \\( b \\) is the bias term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e360f8-102b-4cac-956b-47ef5d687196",
   "metadata": {},
   "source": [
    "# Implementation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b117ea2a-afc1-4b6f-8afb-07eb614baa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc1eb8-3f29-469d-a000-58bb680e14bd",
   "metadata": {},
   "source": [
    "### Mathematical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73be90fe-5e43-4bdc-9afb-d72b6082622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) =  17.0\n",
      "df/dx =  8.0\n"
     ]
    }
   ],
   "source": [
    "#quadratic polynomial function\n",
    "def f(x):\n",
    "    return x**2 + 1\n",
    "\n",
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "y = f(x)\n",
    "print(\"f(x) = \", y.item())\n",
    "\n",
    "#gradient\n",
    "y.backward()\n",
    "print(\"df/dx = \", x.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e544d34-d59c-4911-bff4-6a6e7ef55fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear polynomial function\n",
    "def lin_F(x):\n",
    "    W = torch.tensor([1.0], requires_grad=True)\n",
    "    b = torch.tensor([1.0], requires_grad=True)\n",
    "    \n",
    "    assert x.shape[-1] == W.shape[0], \"\"\"\n",
    "    Invalid shape. (mxn)(nxp) = (mxp). Check shape. W.shape == 1\n",
    "    \"\"\"\n",
    "    return x@W + b, W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297d7dc-1f28-4657-ad67-364d4c5f174f",
   "metadata": {},
   "source": [
    "## Understanding BackProg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd18de24-e063-40f5-b99a-e47c180bb0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3.0\n",
      "Loss =  49.0\n",
      "dL/y_pred (pT)=  -14.0\n",
      "dL/dW (pT)=  -28.0\n",
      "dL/db (pT)=  -14.0\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch's .grad and .backward functions\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y_true = torch.tensor([10.0])\n",
    "\n",
    "#forward pass\n",
    "y_pred, W, b = lin_F(x)\n",
    "print(\"y =\", y_pred.item())\n",
    "\n",
    "#calculate the loss : mean squared error\n",
    "Loss = ((y_true - y_pred)**2).mean()\n",
    "\n",
    "#gradient via PyTorch\n",
    "Loss.backward()\n",
    "print(\"Loss = \", Loss.item())\n",
    "print(\"dL/y_pred (pT)= \", x.grad.item())\n",
    "\n",
    "# Gradient of loss w.r.t W and b\n",
    "print(\"dL/dW (pT)= \", W.grad.item())\n",
    "print(\"dL/db (pT)= \", b.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30342ce6-ed1e-4150-b951-7ac4c5cb9858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3.0\n",
      "dL/dx =  -14.0\n",
      "dL/dW =  -28.0\n",
      "dL/db =  -14.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating gradients manually\n",
    "\n",
    "y_pred, W, b = lin_F(x)\n",
    "man_loss = ((y_true - y_pred)**2).mean()\n",
    "print(\"y =\", y_pred.item())\n",
    "\n",
    "Loss = ((y_true - y_pred)**2).mean()\n",
    "\n",
    "#differentiating Loss w.r.t y_pred (chain-rule)\n",
    "u = y_true - y_pred\n",
    "v = u**2\n",
    "\n",
    "du = -1 \n",
    "dv = 2*u\n",
    "dv_dypred = du*dv\n",
    "\n",
    "dL = dv_dypred.mean()\n",
    "print(\"dL/dx = \", dL.item())\n",
    "\n",
    "#differentiating Loss w.r.t W (chain-rule)\n",
    "dW = dL * x\n",
    "dB = dL*1\n",
    "\n",
    "print(\"dL/dW = \", dW.item())\n",
    "print(\"dL/db = \", dB.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3a218-bb26-4518-97c2-ce9bbbc0c251",
   "metadata": {},
   "source": [
    "## Creating a simple two layers neural network with activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f67161d2-9843-40fb-b7f2-5196c6bb227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1., 1., 1., 1.], requires_grad = True)\n",
    "y = torch.tensor([12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25f9e5b9-8f0d-42b9-8503-9b780161afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 4x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(hidden, W2, b2)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[103], line 11\u001b[0m, in \u001b[0;36mnn\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      9\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(X, W1, b1)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(hidden\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 4x1)"
     ]
    }
   ],
   "source": [
    "#defining a neural network\n",
    "\n",
    "def nn(X):\n",
    "    W1 = torch.tensor([[1., 1., 1., 1.]], requires_grad=True)\n",
    "    b1 = torch.tensor([1.], requires_grad=True)\n",
    "    W2 = torch.tensor([[1., 1., 1., 1.]], requires_grad=True)\n",
    "    b2 = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "    hidden = torch.nn.functional.linear(X, W1, b1)\n",
    "    y_pred = torch.nn.functional.linear(hidden, W2, b2)\n",
    "    \n",
    "    return hidden\n",
    "\n",
    "nn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c7ed363-bc31-4f9b-8908-9346351f9d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120663dc-588f-4952-9942-631b3aa6a9e7",
   "metadata": {},
   "source": [
    "## Example Use Case\n",
    "\n",
    "### Dataset\n",
    "We use a synthetic dataset for demonstration purposes.\n",
    "\n",
    "### Preprocessing\n",
    "No preprocessing is required for this simple dataset.\n",
    "\n",
    "### Training the Model\n",
    "Training the Linear Neural Network using the synthetic dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306592d-b383-40cf-8a2d-f12acda59959",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30529c80-f987-49e4-87b3-72283f99a3e7",
   "metadata": {},
   "source": [
    "## Conclusion and Insights\n",
    "\n",
    "In this notebook, we have explored the fundamentals of Linear Neural Networks and implemented a simple model in PyTorch. Linear models are useful for understanding the basic principles of neural networks and serve as a foundation for more complex architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0ff78-a0b1-451f-95cb-b8b17a39c249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
